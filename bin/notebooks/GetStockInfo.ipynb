{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 3,
=======
   "execution_count": 1,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import requests\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Configs\n",
    "n50_output_data_path_base = r'.\\data\\n50.csv'\n",
    "n50_output_data_path_detailed = r'.\\data\\n50_detailed.csv'\n",
    "excluded_keys_info = ['companyOfficers']\n"
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from io import StringIO\n",
    "import yaml\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_file path\n",
    "aws_api_key_path = r\"..\\\\config\\\\cred_config.yaml\"\n",
    "config_file_path = r\"..\\\\config\\\\config.yaml\"\n",
    "\n",
    "with open(aws_api_key_path,'r') as aws_api_file:\n",
    "    aws_api_config = yaml.safe_load(aws_api_file)\n",
    "\n",
    "with open(config_file_path,'r') as config_file:\n",
    "    config = yaml.safe_load(config_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuring the AWS keys\n",
    "AWS_S3_BUCKET = aws_api_config.get('AWS_S3_BUCKET')\n",
    "AWS_ACCESS_KEY_ID = aws_api_config.get('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY  = aws_api_config.get('AWS_SECRET_ACCESS_KEY')\n",
    "REGION_NAME = aws_api_config.get('REGION_NAME')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-east-1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REGION_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common Configs\n",
    "#n50_output_data_file_name = config.get('n50_output_data_file_name')#'nifty50_raw.csv'\n",
    "#n50_output_detailed_file_name = config.get('n50_output_detailed_file_name')#'nifty50_detailed.csv'\n",
    "\n",
    "index_output_data_file_name = config.get('index_path_50')[1]\n",
    "index_output_detailed_file_name = config.get('index_path_50')[2]\n",
    "index_path = config.get('index_path_50')[0]\n",
    "\n",
    "excluded_keys_info = config.get('excluded_keys_info') #['companyOfficers']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up s3 client\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    region_name = REGION_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the data read from live csv to a buffer then to pandas dataframe without storing it\n",
    "def csvbuffer_to_dataframe(contents):\n",
    "    content_str = contents.decode('utf-8')\n",
    "    content_df = pd.read_csv(StringIO(content_str))\n",
    "    return(content_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the data to s3"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download successful\n"
     ]
    }
   ],
   "source": [
    "# Downlaod the latest data and writing to s3\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/130.0.0.0 Safari/537.36'\n",
    "}\n",
    "\n",
<<<<<<< Updated upstream
    "response = requests.get(\"https://www.niftyindices.com/IndexConstituent/ind_nifty50list.csv\", headers=headers)\n",
    "if response.status_code == 200:\n",
    "    with open(n50_output_data_path_base, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Download successful\")\n",
    "else:\n",
    "    print(\"Failed to download:\", response.status_code)"
=======
    "response = requests.get(index_path, headers=headers)\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 5,
=======
   "execution_count": 74,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "n50 = pd.read_csv(r'.\\data\\n50.csv')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 20,
=======
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_s3 = s3_client.put_object(\n",
    "    Bucket = AWS_S3_BUCKET,\n",
    "    Key = index_output_data_file_name,\n",
    "    Body = contents\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Detailed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n50 = pd.read_csv(io.StringIO(response.content.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
>>>>>>> Stashed changes
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_keys(d,keys):\n",
    "    return {x:d[x] for x in d if x not in keys}"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< Updated upstream
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([without_keys(yf.Ticker(x+'.NS').info,excluded_keys_info) for x in n50['Symbol']]).to_csv(n50_output_data_path_detailed)"
=======
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([without_keys(yf.Ticker(x+'.NS').info,excluded_keys_info) for x in n50['Symbol']]).to_csv(\n",
    "    f\"s3://{AWS_S3_BUCKET}/{index_output_detailed_file_name}\",\n",
    "    index=False,\n",
    "    storage_options={\n",
    "        \"key\": AWS_ACCESS_KEY_ID,\n",
    "        \"secret\" : AWS_SECRET_ACCESS_KEY,\n",
    "    }\n",
    ")\n"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sat_b",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
